% This contents of this file will be inserted into the _Solutions version of the
% output tex document.  Here's an example:

% If assignment with subquestion (1.a) requires a written response, you will
% find the following flag within this document: <SCPD_SUBMISSION_TAG>_1a
% In this example, you would insert the LaTeX for your solution to (1.a) between
% the <SCPD_SUBMISSION_TAG>_1a flags.  If you also constrain your answer between the
% START_CODE_HERE and END_CODE_HERE flags, your LaTeX will be styled as a
% solution within the final document.

% Please do not use the '<SCPD_SUBMISSION_TAG>' character anywhere within your code.  As expected,
% that will confuse the regular expressions we use to identify your solution.
\def\assignmentnum{2 }
\def\assignmentname{Understanding and Implementing Word2Vec}
\def\assignmenttitle{XCS224N Assignment \assignmentnum}
\input{macros}
\begin{document}
    \pagestyle{myheadings} \markboth{}{\assignmenttitle}

% <SCPD_SUBMISSION_TAG>_entire_submission

    This handout includes space for every question that requires a written response.
    Please feel free to use it to handwrite your solutions (legibly, please). If
    you choose to typeset your solutions, the |README.md| for this assignment includes
    instructions to regenerate this handout with your typeset \LaTeX{} solutions.
    \ruleskip

    \LARGE
    1.a
    \normalsize

% <SCPD_SUBMISSION_TAG>_1a
    \begin{answer}
        % ### START CODE HERE ###
        Starting from:
        $$J_{\text{naive-softmax}}(v_c, o, U) = -u_o^T v_c + \log\left(\sum_{w \in \text{Vocab}} \exp(u_w^T v_c)\right)$$

        I am taking the derivative with respect to $v_c$ because that is the gradient we are looking for:

        $$\frac{\partial J}{\partial v_c} = \frac{\partial}{\partial v_c}\left[-u_o^T v_c + \log\left(\sum_{w \in \text{Vocab}} \exp(u_w^T v_c)\right)\right]$$

        For the first term:
        $$\frac{\partial}{\partial v_c}(-u_o^T v_c) = -u_o$$

        For the second term, using chain rule:
        $$\frac{\partial}{\partial v_c}\log\left(\sum_{w \in \text{Vocab}} \exp(u_w^T v_c)\right) = \frac{1}{\sum_{w \in \text{Vocab}} \exp(u_w^T v_c)} \cdot \frac{\partial}{\partial v_c}\left(\sum_{w \in \text{Vocab}} \exp(u_w^T v_c)\right)$$

        $$= \frac{1}{\sum_{w \in \text{Vocab}} \exp(u_w^T v_c)} \cdot \sum_{w \in \text{Vocab}} \exp(u_w^T v_c) \cdot u_w$$

        $$= \sum_{w \in \text{Vocab}} \frac{\exp(u_w^T v_c)}{\sum_{w' \in \text{Vocab}} \exp(u_{w'}^T v_c)} \cdot u_w$$

        The clue is to recognize that $\hat{y}_w = \frac{\exp(u_w^T v_c)}{\sum_{w' \in \text{Vocab}} \exp(u_{w'}^T v_c)}$ which I enter into the equation to get:

        $$= \sum_{w \in \text{Vocab}} \hat{y}_w \cdot u_w = U\hat{y}$$

        And therefore:
        $$\frac{\partial J}{\partial v_c} = -u_o + U\hat{y} = U\hat{y} - Uy = U(\hat{y} - y)$$

        where $y$ is a one-hot vector with 1 at position $o$.
        % ### END CODE HERE ###
    \end{answer}
% <SCPD_SUBMISSION_TAG>_1a
    \clearpage

    \LARGE
    1.b
    \normalsize

% <SCPD_SUBMISSION_TAG>_1b
    \begin{answer}
        % ### START CODE HERE ###
        Starting from:
        $$J_{\text{naive-softmax}}(v_c, o, U) = -u_o^T v_c + \log\left(\sum_{w' \in \text{Vocab}} \exp(u_{w'}^T v_c)\right)$$

        The goal is to find $\frac{\partial J}{\partial u_w}$ for all $w \in \text{Vocab}$.

        Case 1: When $w = o$ (the true outside word)

        $$\frac{\partial J}{\partial u_o} = \frac{\partial}{\partial u_o}\left[-u_o^T v_c + \log\left(\sum_{w' \in \text{Vocab}} \exp(u_{w'}^T v_c)\right)\right]$$

        First term: $\frac{\partial}{\partial u_o}(-u_o^T v_c) = -v_c$

        Second term: Using chain rule (similar to 1.a),
        $$\frac{\partial}{\partial u_o}\log\left(\sum_{w' \in \text{Vocab}} \exp(u_{w'}^T v_c)\right) = \frac{1}{\sum_{w' \in \text{Vocab}} \exp(u_{w'}^T v_c)} \cdot \exp(u_o^T v_c) \cdot v_c$$

        $$= \frac{\exp(u_o^T v_c)}{\sum_{w' \in \text{Vocab}} \exp(u_{w'}^T v_c)} \cdot v_c = \hat{y}_o \cdot v_c$$

        Therefore: $\frac{\partial J}{\partial u_o} = -v_c + \hat{y}_o v_c = (\hat{y}_o - 1)v_c$

        Case 2: When $w \neq o$

        $$\frac{\partial J}{\partial u_w} = \frac{\partial}{\partial u_w}\left[\log\left(\sum_{w' \in \text{Vocab}} \exp(u_{w'}^T v_c)\right)\right]$$

        $$= \frac{1}{\sum_{w' \in \text{Vocab}} \exp(u_{w'}^T v_c)} \cdot \exp(u_w^T v_c) \cdot v_c = \hat{y}_w \cdot v_c$$

        In matrix form: $\frac{\partial J}{\partial U} = v_c(\hat{y} - y)^T$
        % ### END CODE HERE ###
    \end{answer}
% <SCPD_SUBMISSION_TAG>_1b
    \clearpage

% <SCPD_SUBMISSION_TAG>_entire_submission

\end{document}